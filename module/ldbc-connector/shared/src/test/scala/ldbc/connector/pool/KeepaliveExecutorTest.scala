/**
 * Copyright (c) 2023-2025 by Takahiko Tominaga
 * This software is licensed under the MIT License (MIT).
 * For more information see LICENSE or https://opensource.org/licenses/MIT
 */

package ldbc.connector.pool

import scala.concurrent.duration.*

import cats.syntax.all.*

import cats.effect.*

import ldbc.connector.*
import ldbc.sql.*

class KeepaliveExecutorTest extends FTestPlatform:

  // Helper to create a mock Connection for testing
  private def createMockConnection[F[_]: Temporal](
    validationCount: Ref[F, Int],
    isValidResult: Boolean = true
  ): Connection[F] =
    new Connection[F]:
      override def isValid(timeout: Int): F[Boolean] = 
        validationCount.update(_ + 1) >> Temporal[F].pure(isValidResult)
      
      override def createStatement(): F[Statement[F]] = 
        Temporal[F].pure(new Statement[F] {
          override def execute(sql: String): F[Boolean] = Temporal[F].pure(true)
          override def close(): F[Unit] = Temporal[F].unit
          override def executeQuery(sql: String): F[ResultSet[F]] = ???
          override def executeUpdate(sql: String): F[Int] = ???
          override def getResultSet(): F[Option[ResultSet[F]]] = ???
          override def getUpdateCount(): F[Int] = ???
          override def getMoreResults(): F[Boolean] = ???
          override def setFetchSize(rows: Int): F[Unit] = Temporal[F].unit
          override def getFetchSize(): F[Int] = Temporal[F].pure(0)
          override def addBatch(sql: String): F[Unit] = Temporal[F].unit
          override def clearBatch(): F[Unit] = Temporal[F].unit
          override def executeBatch(): F[Array[Int]] = ???
          override def getGeneratedKeys(): F[ResultSet[F]] = ???
          override def executeUpdate(sql: String, autoGeneratedKeys: Int): F[Int] = ???
          override def execute(sql: String, autoGeneratedKeys: Int): F[Boolean] = ???
          override def isClosed(): F[Boolean] = Temporal[F].pure(false)
          override def getLargeUpdateCount(): F[Long] = ???
          override def executeLargeUpdate(sql: String): F[Long] = ???
          override def executeLargeUpdate(sql: String, autoGeneratedKeys: Int): F[Long] = ???
          override def executeLargeBatch(): F[Array[Long]] = ???
        })
      
      override def isClosed(): F[Boolean] = Temporal[F].pure(false)
      override def close(): F[Unit] = Temporal[F].unit
      override def prepareStatement(sql: String): F[PreparedStatement[F]] = ???
      override def prepareCall(sql: String): F[CallableStatement[F]] = ???
      override def nativeSQL(sql: String): F[String] = ???
      override def getAutoCommit(): F[Boolean] = Temporal[F].pure(true)
      override def setAutoCommit(autoCommit: Boolean): F[Unit] = Temporal[F].unit
      override def commit(): F[Unit] = Temporal[F].unit
      override def rollback(): F[Unit] = Temporal[F].unit
      override def getTransactionIsolation(): F[Int] = Temporal[F].pure(0)
      override def setTransactionIsolation(level: Int): F[Unit] = Temporal[F].unit
      override def isReadOnly: F[Boolean] = Temporal[F].pure(false)
      override def setReadOnly(readOnly: Boolean): F[Unit] = Temporal[F].unit
      override def getCatalog(): F[String] = Temporal[F].pure("")
      override def setCatalog(catalog: String): F[Unit] = Temporal[F].unit
      override def getMetaData(): F[DatabaseMetaData[F]] = ???
      override def setSavepoint(): F[Savepoint] = ???
      override def setSavepoint(name: String): F[Savepoint] = ???
      override def releaseSavepoint(savepoint: Savepoint): F[Unit] = Temporal[F].unit
      override def rollback(savepoint: Savepoint): F[Unit] = Temporal[F].unit
      override def createStatement(resultSetType: Int, resultSetConcurrency: Int): F[Statement[F]] = ???
      override def prepareStatement(sql: String, resultSetType: Int, resultSetConcurrency: Int): F[PreparedStatement[F]] = ???
      override def prepareCall(sql: String, resultSetType: Int, resultSetConcurrency: Int): F[CallableStatement[F]] = ???
      override def prepareStatement(sql: String, autoGeneratedKeys: Int): F[PreparedStatement[F]] = ???
      override def setSchema(schema: String): F[Unit] = Temporal[F].unit
      override def getSchema(): F[String] = Temporal[F].pure("")

  // Helper to create a pooled connection
  private def createPooledConnection[F[_]: Temporal](
    id: String,
    connection: Connection[F],
    createdAt: Long,
    lastUsedAt: Long
  ): F[PooledConnection[F]] = for
    stateRef         <- Ref[F].of(ConnectionState.Idle)
    lastUsedRef      <- Ref[F].of(lastUsedAt)
    useCountRef      <- Ref[F].of(0L)
    lastValidatedRef <- Ref[F].of(createdAt)
    leakDetectionRef <- Ref[F].of(Option.empty[Fiber[F, Throwable, Unit]])
    bagStateRef      <- Ref[F].of(BagEntry.STATE_NOT_IN_USE)
  yield PooledConnection[F](
    id              = id,
    connection      = connection,
    finalizer       = Temporal[F].unit,
    state           = stateRef,
    createdAt       = createdAt,
    lastUsedAt      = lastUsedRef,
    useCount        = useCountRef,
    lastValidatedAt = lastValidatedRef,
    leakDetection   = leakDetectionRef,
    bagState        = bagStateRef
  )

  // Mock PooledDataSource for testing
  private class MockPooledDataSource[F[_]: Temporal](
    tracker: PoolMetricsTracker[F],
    poolStateRef: Ref[F, PoolState[F]],
    validationFunc: Connection[F] => F[Boolean]
  ) extends PooledDataSource[F]:
    override def minConnections = 2
    override def maxConnections = 5
    override def connectionTimeout = 1.second
    override def idleTimeout = 5.minutes
    override def maxLifetime = 10.minutes
    override def validationTimeout = 1.second
    override def leakDetectionThreshold = None
    override def adaptiveSizing = false
    override def adaptiveInterval = 30.seconds
    override def metricsTracker = tracker
    override def poolState = poolStateRef
    override def idGenerator = Temporal[F].pure(java.util.UUID.randomUUID().toString)
    override def houseKeeper = None
    override def adaptiveSizer = None
    override def keepaliveExecutor = None
    override def aliveBypassWindow = 0.seconds
    override def keepaliveTime = None
    override def connectionTestQuery = None
    override def circuitBreaker = ???
    override def getConnection = ???
    override def status = poolStateRef.get.map(s => PoolStatus(
      total = s.connections.size,
      idle = s.idleConnections.size,
      active = s.connections.size - s.idleConnections.size,
      waiting = s.waitQueue.size
    ))
    override def metrics = Temporal[F].pure(PoolMetrics.empty)
    override def close = Temporal[F].unit
    override def createNewConnection() = ???
    override def createNewConnectionForPool() = ???
    override def returnToPool(pooled: PooledConnection[F]) = Temporal[F].unit
    override def removeConnection(pooled: PooledConnection[F]) = Temporal[F].unit
    override def validateConnection(conn: Connection[F]) = validationFunc(conn)

  test("KeepaliveExecutor should start and stop correctly") {
    for
      tracker        <- PoolMetricsTracker.inMemory[IO]
      validatedCount <- Ref[IO].of(0)
      keepalive      = KeepaliveExecutor.fromAsync[IO](100.milliseconds, tracker)
      
      // Start and immediately stop
      _ <- keepalive.start(new MockPooledDataSource[IO](tracker, Ref.unsafe[IO, PoolState[IO]](PoolState.empty), _ => IO.pure(true))).use { _ =>
             IO.sleep(50.milliseconds) // Run briefly
           }
      
      // Should have stopped cleanly
      count <- validatedCount.get
    yield
      // May or may not have run depending on timing
      assert(count >= 0)
  }

  test("KeepaliveExecutor should validate idle connections") {
    for
      tracker         <- PoolMetricsTracker.inMemory[IO]
      validationCount <- Ref[IO].of(0)
      now             <- Clock[IO].realTime.map(_.toMillis)
      
      // Create mock connections
      conn1 <- IO.pure(createMockConnection[IO](validationCount))
      conn2 <- IO.pure(createMockConnection[IO](validationCount))
      
      // Create pooled connections
      pooledConn1 <- createPooledConnection[IO]("conn-1", conn1, now, now - 1000)
      pooledConn2 <- createPooledConnection[IO]("conn-2", conn2, now, now - 2000)
      
      // Create pool state
      poolState <- Ref[IO].of(PoolState[IO](
        connections = Vector(pooledConn1, pooledConn2),
        idleConnections = Set("conn-1", "conn-2"),
        waitQueue = Vector.empty,
        metrics = PoolMetrics.empty,
        closed = false
      ))
      
      pool = new MockPooledDataSource[IO](tracker, poolState, _.isValid(1))
      keepalive = KeepaliveExecutor.fromAsync[IO](100.milliseconds, tracker)
      
      // Run keepalive for a short time
      _ <- keepalive.start(pool).use { _ =>
             IO.sleep(250.milliseconds)
           }
      
      count <- validationCount.get
    yield
      // Should have validated idle connections at least once
      assert(count >= 2, s"Expected at least 2 validations, got $count")
  }

  test("KeepaliveExecutor should handle validation failures") {
    for
      tracker         <- PoolMetricsTracker.inMemory[IO]
      validationCount <- Ref[IO].of(0)
      now             <- Clock[IO].realTime.map(_.toMillis)
      
      // Create connections - one valid, one invalid
      validConn   <- IO.pure(createMockConnection[IO](validationCount, isValidResult = true))
      invalidConn <- IO.pure(createMockConnection[IO](validationCount, isValidResult = false))
      
      // Create pooled connections
      pooledConn1 <- createPooledConnection[IO]("conn-1", validConn, now, now)
      pooledConn2 <- createPooledConnection[IO]("conn-2", invalidConn, now, now)
      
      // Create pool state
      poolState <- Ref[IO].of(PoolState[IO](
        connections = Vector(pooledConn1, pooledConn2),
        idleConnections = Set("conn-1", "conn-2"),
        waitQueue = Vector.empty,
        metrics = PoolMetrics.empty,
        closed = false
      ))
      
      pool = new MockPooledDataSource[IO](tracker, poolState, _.isValid(1))
      keepalive = KeepaliveExecutor.fromAsync[IO](100.milliseconds, tracker)
      
      // Run keepalive
      _ <- keepalive.start(pool).use { _ =>
             IO.sleep(250.milliseconds)
           }
      
      count <- validationCount.get
      finalState <- poolState.get
    yield
      // Should have attempted validations
      assert(count >= 2, s"Expected at least 2 validation attempts, got $count")
      // Invalid connection might be removed from idle set
      assert(finalState.idleConnections.size <= 2)
  }

  test("KeepaliveExecutor should respect intervals with variance") {
    for
      tracker           <- PoolMetricsTracker.inMemory[IO]
      validationTimes   <- Ref[IO].of(List.empty[Long])
      validationCount   <- Ref[IO].of(0)
      now               <- Clock[IO].realTime.map(_.toMillis)
      
      // Create connection that tracks validation times
      conn = new Connection[IO]:
        override def isValid(timeout: Int): IO[Boolean] = 
          for
            currentTime <- Clock[IO].realTime.map(_.toMillis)
            _           <- validationTimes.update(currentTime :: _)
            _           <- validationCount.update(_ + 1)
          yield true
        
        // Delegate other methods to mock
        private val delegate = createMockConnection[IO](Ref.unsafe[IO, Int](0))
        export delegate.{isValid as _, *}
      
      // Create pooled connection
      pooledConn <- createPooledConnection[IO]("conn-1", conn, now, now)
      
      // Create pool state
      poolState <- Ref[IO].of(PoolState[IO](
        connections = Vector(pooledConn),
        idleConnections = Set("conn-1"),
        waitQueue = Vector.empty,
        metrics = PoolMetrics.empty,
        closed = false
      ))
      
      pool = new MockPooledDataSource[IO](tracker, poolState, _.isValid(1))
      keepalive = KeepaliveExecutor.fromAsync[IO](200.milliseconds, tracker)
      
      // Run keepalive for multiple intervals
      _ <- keepalive.start(pool).use { _ =>
             IO.sleep(1.second)
           }
      
      times <- validationTimes.get.map(_.reverse)
      count <- validationCount.get
    yield
      // Should have multiple validations
      assert(count >= 3, s"Expected at least 3 validations, got $count")
      
      // Check intervals between validations
      if times.length >= 2 then
        val intervals = times.zip(times.tail).map { case (t1, t2) => t2 - t1 }
        intervals.foreach { interval =>
          // Base interval is 200ms, with 20% variance = 160-240ms range
          assert(interval >= 160, s"Interval $interval too short (expected >= 160ms)")
          assert(interval <= 240, s"Interval $interval too long (expected <= 240ms)")
        }
  }

  test("KeepaliveExecutor should stop when pool is closed") {
    for
      tracker         <- PoolMetricsTracker.inMemory[IO]
      validationCount <- Ref[IO].of(0)
      now             <- Clock[IO].realTime.map(_.toMillis)
      
      conn <- IO.pure(createMockConnection[IO](validationCount))
      pooledConn <- createPooledConnection[IO]("conn-1", conn, now, now)
      
      // Create pool state
      poolState <- Ref[IO].of(PoolState[IO](
        connections = Vector(pooledConn),
        idleConnections = Set("conn-1"),
        waitQueue = Vector.empty,
        metrics = PoolMetrics.empty,
        closed = false
      ))
      
      pool = new MockPooledDataSource[IO](tracker, poolState, _.isValid(1))
      keepalive = KeepaliveExecutor.fromAsync[IO](100.milliseconds, tracker)
      
      _ <- keepalive.start(pool).use { _ =>
                 for
                   // Let it run a bit
                   _      <- IO.sleep(150.milliseconds)
                   count1 <- validationCount.get
                   
                   // Mark pool as closed
                   _ <- poolState.update(_.copy(closed = true))
                   
                   // Wait and check it stopped
                   _      <- IO.sleep(300.milliseconds)
                   count2 <- validationCount.get
                 yield
                   assert(count1 > 0, "Should have validated before closing")
                   assertEquals(count1, count2, "Should not validate after pool is closed")
               }
    yield ()
  }

  // Integration test with real database
  private val config = MySQLConfig.default
    .setPort(13306)
    .setUser("ldbc")
    .setPassword("password")
    .setDatabase("connector_test")
    .setSSL(SSL.Trusted)

  test("KeepaliveExecutor should work with real database connections") {
    val testConfig = config
      .setMinConnections(2)
      .setMaxConnections(5)
      .setKeepaliveTime(30.seconds) // Minimum allowed
      .setValidationTimeout(1.second)

    val resource = for
      tracker <- Resource.eval(PoolMetricsTracker.inMemory[IO])
      ds      <- PooledDataSource.fromConfig[IO](testConfig, metricsTracker = Some(tracker))
    yield (ds, tracker)

    resource.use {
      case (datasource, tracker) =>
        for
          // Get initial state
          initialStatus  <- datasource.status
          initialMetrics <- tracker.getMetrics
          
          // Use some connections to make them idle
          _ <- datasource.getConnection.use { conn =>
                 conn.createStatement().flatMap(_.executeQuery("SELECT 1")).void
               }
          
          // Wait a bit (not full keepalive interval due to time constraints)
          _ <- IO.sleep(2.seconds)
          
          // Check state is maintained
          finalStatus  <- datasource.status
          finalMetrics <- tracker.getMetrics
        yield
          assertEquals(initialStatus.total, 2)
          assertEquals(finalStatus.total, 2)
          // Connections should remain healthy
          assert(finalStatus.idle >= 1)
          // Should have acquisition from our usage
          assert(finalMetrics.totalAcquisitions >= 1L)
    }
  }